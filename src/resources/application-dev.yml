# application-dev.yml - 개발 환경 설정
spring:
  # 데이터베이스 설정 (개발용 H2)
  datasource:
    url: jdbc:h2:mem:devdb;DB_CLOSE_DELAY=-1;DB_CLOSE_ON_EXIT=FALSE
    username: sa
    password: 
    driver-class-name: org.h2.Driver
    hikari:
      maximum-pool-size: 10
      minimum-idle: 2
      connection-timeout: 20000
  
  # H2 콘솔 활성화
  h2:
    console:
      enabled: true
      path: /h2-console
      settings:
        web-allow-others: true
        trace: false
  
  # JPA 설정 (개발용)
  jpa:
    hibernate:
      ddl-auto: create-drop
    show-sql: true
    properties:
      hibernate:
        dialect: org.hibernate.dialect.H2Dialect
        format_sql: true
        use_sql_comments: true
        jdbc:
          batch_size: 10
        cache:
          use_second_level_cache: false
          use_query_cache: false
  
  # Redis 설정 (개발용)
  data:
    redis:
      host: localhost
      port: 6379
      password: 
      database: 1  # 개발용 DB
      timeout: 5000ms
      lettuce:
        pool:
          max-active: 4
          max-idle: 4
          min-idle: 1
  
  # 개발용 웹 설정
  web:
    resources:
      add-mappings: true
      cache:
        cachecontrol:
          max-age: 0
          must-revalidate: true
  
  # 핫 리로드 설정
  devtools:
    restart:
      enabled: true
      additional-paths: src/main/java
      exclude: static/**,public/**
    livereload:
      enabled: true
      port: 35729

# 서버 설정 (개발용)
server:
  port: 8080
  error:
    include-message: always
    include-binding-errors: always
    include-stacktrace: always
    include-exception: true
  servlet:
    session:
      timeout: 30m

# 액추에이터 설정 (개발용)
management:
  endpoints:
    web:
      exposure:
        include: "*"  # 개발환경에서는 모든 엔드포인트 노출
  endpoint:
    health:
      show-details: always
    shutdown:
      enabled: true
  security:
    enabled: false

# LLM 개발 설정
llm:
  # 개발용 모델 설정
  models:
    - name: "gpt-3.5-turbo-dev"
      provider: "openai"
      endpoint: "https://api.openai.com/v1/chat/completions"
      apiKey: "${OPENAI_API_KEY:sk-fake-key-for-dev}"
      maxTokens: 1000  # 개발용으로 제한
      temperature: 0.7
      enabled: true
      limits:
        maxRequestsPerMinute: 20  # 개발용으로 제한
        maxTokensPerMinute: 10000
        maxConcurrentRequests: 3
        maxContextLength: 4096
        costPerInputToken: 0.0015
        costPerOutputToken: 0.002
      features:
        supportsStreaming: true
        supportsSystemPrompt: true
        supportsFunctionCalling: true
        supportsVision: false
        supportsEmbeddings: false
    
    - name: "ollama-llama3-dev"
      provider: "ollama"
      endpoint: "http://localhost:11434/api/generate"
      model: "llama3:8b"
      maxTokens: 2048
      temperature: 0.7
      enabled: false  # 기본적으로 비활성화
      limits:
        maxRequestsPerMinute: 30
        maxTokensPerMinute: 20000
        maxConcurrentRequests: 2
        maxContextLength: 8192
        costPerInputToken: 0.0
        costPerOutputToken: 0.0
      features:
        supportsStreaming: true
        supportsSystemPrompt: true
        supportsFunctionCalling: false
        supportsVision: false
        supportsEmbeddings: false
    
    # 개발용 더미 모델
    - name: "mock-model"
      provider: "mock"
      endpoint: "http://localhost:8080/mock"
      maxTokens: 1000
      temperature: 0.7
      enabled: true
      limits:
        maxRequestsPerMinute: 1000
        maxTokensPerMinute: 100000
        maxConcurrentRequests: 10
        maxContextLength: 4096
        costPerInputToken: 0.0
        costPerOutputToken: 0.0
      features:
        supportsStreaming: true
        supportsSystemPrompt: true
        supportsFunctionCalling: true
        supportsVision: false
        supportsEmbeddings: true
  
  # 개발용 기본 설정
  defaults:
    model: "mock-model"
    timeout: 10000  # 개발용으로 짧게
    retryAttempts: 1  # 개발용으로 적게
    retryDelayMs: 500
    retryMultiplier: 1.5
    enableCircuitBreaker: false  # 개발환경에서는 비활성화
    enableMetrics: true
    enableCaching: false  # 개발환경에서는 캐시 비활성화
  
  # 개발용 보안 설정 (느슨함)
  security:
    enableApiKeyValidation: false  # 개발환경에서는 비활성화
    enableRateLimiting: false
    enableRequestLogging: true   # 개발환경에서는 활성화
    enableResponseLogging: true
    maskSensitiveData: false    # 개발환경에서는 비활성화
    allowedOrigins:
      - "*"
    requestsPerMinute: 1000
  
  # 개발용 모니터링 설정
  monitoring:
    enableHealthChecks: true
    enableMetrics: true
    enableAlerts: false  # 개발환경에서는 알럿 비활성화
    enablePerformanceTracking: true
    healthCheckIntervalSeconds: 10  # 더 자주 체크
    metricsIntervalSeconds: 30
    alertCheckIntervalSeconds: 60
  
  # 개발용 캐시 설정
  cache:
    enableResponseCaching: false
    enableModelInfoCaching: false
    enableConfigCaching: false
    defaultTtlSeconds: 300   # 5분
    responseCacheTtlSeconds: 600  # 10분
    modelInfoCacheTtlSeconds: 300
    configCacheTtlSeconds: 180
    maxCacheSizeMb: 64
    enableCacheMetrics: true
    enableCacheCompression: false
  
  # 개발용 에러 설정
  error:
    include-stack-trace: true
    include-sensitive-info: true

# vLLM 개발 설정
vllm:
  servers:
    - name: "llama3-dev-server"
      model: "meta-llama/Meta-Llama-3-8B-Instruct"
      port: 8001
      host: "localhost"
      enabled: false  # 기본적으로 비활성화
      modelSettings:
        maxModelLen: 2048
        maxNumSeqs: 16
        dtype: "auto"
        trustRemoteCode: false
      performanceSettings:
        gpuMemoryUtilization: 0.7
        tensorParallelSize: 1
        pipelineParallelSize: 1
        disableLogStats: false
      quantizationSettings:
        quantization: null
        loadFormat: "auto"
        enforceEager: false
  
  globalSettings:
    seed: 42
    logLevel: "DEBUG"
    disableLogRequests: false
    requestTimeout: 60000
    enableMetrics: true
  
  resourceSettings:
    device: "auto"
    gpuIds: [0]
    numGpus: 1
  
  securitySettings:
    sslEnabled: false
    corsEnabled: true
    allowedOrigins: ["*"]

# 로깅 설정 (개발용)
logging:
  level:
    root: INFO
    com.yourcompany.llm: DEBUG
    org.springframework.web: DEBUG
    org.springframework.security: DEBUG
    org.hibernate.SQL: DEBUG
    org.hibernate.type.descriptor.sql.BasicBinder: TRACE
    org.springframework.cache: DEBUG
    redis.clients.jedis: DEBUG
    io.lettuce.core: DEBUG
    org.springframework.data.redis: DEBUG
  pattern:
    console: "%clr(%d{HH:mm:ss.SSS}){faint} %clr([%thread]){faint} %clr(%-5level){highlight} %clr(%logger{36}){cyan} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n"
  file:
    name: logs/llm-api-dev.log

# 개발용 외부 API 설정
api:
  openai:
    baseUrl: "https://api.openai.com/v1"
    timeout: 10000
    maxRetries: 1
  anthropic:
    baseUrl: "https://api.anthropic.com/v1"
    timeout: 10000
    maxRetries: 1
  ollama:
    baseUrl: "http://localhost:11434/api"
    timeout: 30000
    maxRetries: 2

# 개발용 보안 설정
security:
  jwt:
    secret: "dev-secret-key-not-for-production"
    expiration: 86400000
  cors:
    allowed-origins: 
      - "http://localhost:3000"
      - "http://localhost:3001"
      - "http://localhost:8080"
      - "http://127.0.0.1:3000"
    allowed-methods: "*"
    allowed-headers: "*"
    allow-credentials: true
    max-age: 3600

# 스웨거 설정 (개발용)
springdoc:
  api-docs:
    enabled: true
    path: /api-docs
  swagger-ui:
    enabled: true
    path: /swagger-ui.html
    operations-sorter: method
    tags-sorter: alpha
    try-it-out-enabled: true
    filter: true
    doc-expansion: list
    default-models-expand-depth: 3
    default-model-expand-depth: 3
  show-actuator: true

# 개발용 프로파일링
debug: true

# 테스트용 데이터 초기화
app:
  init:
    create-sample-data: true
    sample-users: 5
    sample-conversations: 10
    sample-messages: 50

# 개발용 메모리 설정
spring.jpa.properties.hibernate.jdbc.batch_size: 5